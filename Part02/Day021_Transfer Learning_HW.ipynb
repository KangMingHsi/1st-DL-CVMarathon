{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 使用Xception backbone做 Trnasfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解如何使用Transfer Learning\n",
    "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 可以自行嘗試多種架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 7, 7, 128)    512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 256)    32768       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 4, 4, 256)    1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 2, 728)    186368      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 2, 2, 728)    2912        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 1024)   745472      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1, 1, 1024)   4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Input\n",
    " \n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "#include top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "'''Xception 架構'''\n",
    "model=keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
    "                                    input_tensor=input_tensor,\n",
    "                                    pooling=None, classes=10)\n",
    "\n",
    "'''Resnet 50 架構'''\n",
    "#model=keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "                                    #input_tensor=input_tensor,\n",
    "                                    #pooling=None, classes=10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加層數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "W1223 14:21:25.017072  4296 deprecation.py:506] From C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model深度： 136\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "\n",
    "'''可以參考Cifar10實作章節'''\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(p=0.1)(x)\n",
    "\n",
    "predictions = Dense(units=10,activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "print('Model深度：', len(model.layers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 鎖定特定幾層不要更新權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備 Cifar 10 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7)\n",
    "        return X_train, X_test\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1223 14:21:42.719341  4296 module_wrapper.py:139] From C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1223 14:21:42.733354  4296 module_wrapper.py:139] From C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1223 14:21:42.795410  4296 deprecation.py:323] From C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1223 14:21:43.085675  4296 module_wrapper.py:139] From C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1223 14:21:43.382944  4296 module_wrapper.py:139] From C:\\Users\\SeanKang\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 1.3985 - acc: 0.5129\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 1.0281 - acc: 0.6470\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.9079 - acc: 0.6872\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.8276 - acc: 0.7150\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.7433 - acc: 0.7448\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.6814 - acc: 0.7669\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.6128 - acc: 0.7887\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.5576 - acc: 0.8086\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.4912 - acc: 0.8308\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.4532 - acc: 0.8438\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.4103 - acc: 0.8591\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3760 - acc: 0.8713\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 84s 2ms/step - loss: 0.3398 - acc: 0.8836\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.3192 - acc: 0.8903\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.2946 - acc: 0.8989\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.2811 - acc: 0.9026\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.2658 - acc: 0.9090\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.2537 - acc: 0.9141\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 43s 858us/step - loss: 0.2344 - acc: 0.9202\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 42s 847us/step - loss: 0.2253 - acc: 0.9242\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 42s 845us/step - loss: 0.2192 - acc: 0.9250\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.2057 - acc: 0.9304\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1979 - acc: 0.9332\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1930 - acc: 0.9346\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1876 - acc: 0.9369\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1836 - acc: 0.9381\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1744 - acc: 0.9411\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1679 - acc: 0.9444\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1717 - acc: 0.9424\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1607 - acc: 0.9459\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1566 - acc: 0.9472\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1486 - acc: 0.9501\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1485 - acc: 0.9503\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.1416 - acc: 0.9518\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1378 - acc: 0.9546\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1373 - acc: 0.9545\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.1344 - acc: 0.9548\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 0.1351 - acc: 0.9560\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 118s 2ms/step - loss: 0.1287 - acc: 0.9574\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 107s 2ms/step - loss: 0.1267 - acc: 0.9594\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.1241 - acc: 0.9578\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1198 - acc: 0.9608\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 0.1168 - acc: 0.9610\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 0.1178 - acc: 0.9603\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.1148 - acc: 0.9614\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1083 - acc: 0.9641\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.1138 - acc: 0.9620\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.1073 - acc: 0.9653\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 81s 2ms/step - loss: 0.1040 - acc: 0.9665\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1100 - acc: 0.9649\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1007 - acc: 0.9664\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0996 - acc: 0.9662\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.1027 - acc: 0.9660\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0945 - acc: 0.9691\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0971 - acc: 0.9676\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0973 - acc: 0.9678\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0931 - acc: 0.9688\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 0.0904 - acc: 0.9713\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0939 - acc: 0.9704\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0931 - acc: 0.9701\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0892 - acc: 0.9717\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0862 - acc: 0.9729\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0867 - acc: 0.9711\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0858 - acc: 0.9723: 0s - loss: 0.0858 - acc\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0860 - acc: 0.9719\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 0.0786 - acc: 0.9739\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 0.0822 - acc: 0.9738\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0844 - acc: 0.9735\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 124s 2ms/step - loss: 0.0812 - acc: 0.9736\n",
      "Epoch 70/100\n",
      "41888/50000 [========================>.....] - ETA: 20s - loss: 0.0765 - acc: 0.9750"
     ]
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
